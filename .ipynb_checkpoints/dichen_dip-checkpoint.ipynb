{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Image Processing: Otsu and Adaptive Gaussian Thresholding\n",
    "\n",
    "This notebook processes all images in a folder using two thresholding methods:\n",
    "1. **Otsu Global Thresholding**\n",
    "2. **Adaptive Gaussian Thresholding**\n",
    "\n",
    "Processed images are saved to separate output folders with the same filenames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_otsu_threshold(gray_image: np.ndarray) -> int:\n",
    "    \"\"\"Compute Otsu's threshold by maximizing between-class variance.\"\"\"\n",
    "    hist, _ = np.histogram(gray_image.flatten(), bins=256, range=(0, 256))\n",
    "    hist = hist.astype(float)\n",
    "    total_pixels = gray_image.size\n",
    "    prob = hist / total_pixels\n",
    "    \n",
    "    omega = np.cumsum(prob)\n",
    "    mu = np.cumsum(prob * np.arange(256))\n",
    "    mu_total = mu[-1]\n",
    "    \n",
    "    valid_indices = (omega > 0) & (omega < 1)\n",
    "    between_class_variance = np.zeros(256)\n",
    "    between_class_variance[valid_indices] = (\n",
    "        (mu_total * omega[valid_indices] - mu[valid_indices]) ** 2 / \n",
    "        (omega[valid_indices] * (1 - omega[valid_indices]))\n",
    "    )\n",
    "    \n",
    "    optimal_threshold = np.argmax(between_class_variance)\n",
    "    return optimal_threshold\n",
    "\n",
    "\n",
    "def otsu_global_thresholding(image: np.ndarray, \n",
    "                             blur_ksize: int = 5,\n",
    "                             morph_ksize: int = 3) -> np.ndarray:\n",
    "    \"\"\"Apply Otsu's global thresholding with preprocessing and morphological operations.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (blur_ksize, blur_ksize), 0)\n",
    "    threshold = compute_otsu_threshold(blurred)\n",
    "    _, binary = cv2.threshold(blurred, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_ksize, morph_ksize))\n",
    "    opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    result = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def adaptive_gaussian_thresholding(image: np.ndarray,\n",
    "                                   window_size: int = 25,\n",
    "                                   C: int = 5,\n",
    "                                   morph_ksize: int = 3) -> np.ndarray:\n",
    "    \"\"\"Apply adaptive Gaussian thresholding with local neighborhood statistics.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        gray,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        window_size,\n",
    "        C\n",
    "    )\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_ksize, morph_ksize))\n",
    "    opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    result = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input folder path (folder containing JPG images)\n",
    "input_folder = 'images'  # Change this to your input folder path\n",
    "\n",
    "# Output folder paths\n",
    "output_folder_otsu = 'dichen_output_otsu'\n",
    "output_folder_adaptiveGaussian = 'dichen_output_adaptiveGaussian'\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_folder_otsu, exist_ok=True)\n",
    "os.makedirs(output_folder_adaptiveGaussian, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 images to process\n",
      "Processed: alpr_lp_61.jpg\n",
      "Processed: alpr_lp_167.jpg\n",
      "Processed: alpr_lp_160.jpg\n",
      "Processed: alpr_lp_66.jpg\n",
      "Processed: alpr_lp_14.jpg\n",
      "Processed: alpr_lp_68.jpg\n",
      "Processed: alpr_lp_112.jpg\n",
      "Processed: alpr_lp_115.jpg\n",
      "Processed: alpr_lp_13.jpg\n",
      "Processed: alpr_lp_169.jpg\n",
      "Processed: alpr_lp_120.jpg\n",
      "Processed: alpr_lp_26.jpg\n",
      "Processed: alpr_lp_21.jpg\n",
      "Processed: alpr_lp_127.jpg\n",
      "Processed: alpr_lp_184.jpg\n",
      "Processed: alpr_lp_155.jpg\n",
      "Processed: alpr_lp_82.jpg\n",
      "Processed: alpr_lp_129.jpg\n",
      "Processed: alpr_lp_53.jpg\n",
      "Processed: alpr_lp_85.jpg\n",
      "Processed: alpr_lp_54.jpg\n",
      "Processed: alpr_lp_183.jpg\n",
      "Processed: alpr_lp_152.jpg\n",
      "Processed: alpr_lp_28.jpg\n",
      "Processed: alpr_lp_45.jpg\n",
      "Processed: alpr_lp_94.jpg\n",
      "Processed: alpr_lp_39.jpg\n",
      "Processed: alpr_lp_143.jpg\n",
      "Processed: alpr_lp_192.jpg\n",
      "Processed: alpr_lp_144.jpg\n",
      "Processed: alpr_lp_195.jpg\n",
      "Processed: alpr_lp_42.jpg\n",
      "Processed: alpr_lp_138.jpg\n",
      "Processed: alpr_lp_93.jpg\n",
      "Processed: alpr_lp_30.jpg\n",
      "Processed: alpr_lp_136.jpg\n",
      "Processed: alpr_lp_131.jpg\n",
      "Processed: alpr_lp_37.jpg\n",
      "Processed: alpr_lp_104.jpg\n",
      "Processed: alpr_lp_7.jpg\n",
      "Processed: alpr_lp_178.jpg\n",
      "Processed: alpr_lp_103.jpg\n",
      "Processed: alpr_lp_79.jpg\n",
      "Processed: alpr_lp_171.jpg\n",
      "Processed: alpr_lp_77.jpg\n",
      "Processed: alpr_lp_70.jpg\n",
      "Processed: alpr_lp_9.jpg\n",
      "Processed: alpr_lp_176.jpg\n",
      "Processed: alpr_lp_84.jpg\n",
      "Processed: alpr_lp_55.jpg\n",
      "Processed: alpr_lp_182.jpg\n",
      "Processed: alpr_lp_29.jpg\n",
      "Processed: alpr_lp_153.jpg\n",
      "Processed: alpr_lp_185.jpg\n",
      "Processed: alpr_lp_154.jpg\n",
      "Processed: alpr_lp_83.jpg\n",
      "Processed: alpr_lp_52.jpg\n",
      "Processed: alpr_lp_128.jpg\n",
      "Processed: alpr_lp_20.jpg\n",
      "Processed: alpr_lp_126.jpg\n",
      "Processed: alpr_lp_121.jpg\n",
      "Processed: alpr_lp_27.jpg\n",
      "Processed: alpr_lp_114.jpg\n",
      "Processed: alpr_lp_168.jpg\n",
      "Processed: alpr_lp_12.jpg\n",
      "Processed: alpr_lp_15.jpg\n",
      "Processed: alpr_lp_113.jpg\n",
      "Processed: alpr_lp_69.jpg\n",
      "Processed: alpr_lp_161.jpg\n",
      "Processed: alpr_lp_67.jpg\n",
      "Processed: alpr_lp_60.jpg\n",
      "Processed: alpr_lp_166.jpg\n",
      "Processed: alpr_lp_71.jpg\n",
      "Processed: alpr_lp_8.jpg\n",
      "Processed: alpr_lp_177.jpg\n",
      "Processed: alpr_lp_170.jpg\n",
      "Processed: alpr_lp_76.jpg\n",
      "Processed: alpr_lp_78.jpg\n",
      "Processed: alpr_lp_102.jpg\n",
      "Processed: alpr_lp_1.jpg\n",
      "Processed: alpr_lp_105.jpg\n",
      "Processed: alpr_lp_6.jpg\n",
      "Processed: alpr_lp_179.jpg\n",
      "Processed: alpr_lp_130.jpg\n",
      "Processed: alpr_lp_36.jpg\n",
      "Processed: alpr_lp_31.jpg\n",
      "Processed: alpr_lp_137.jpg\n",
      "Processed: alpr_lp_145.jpg\n",
      "Processed: alpr_lp_194.jpg\n",
      "Processed: alpr_lp_139.jpg\n",
      "Processed: alpr_lp_43.jpg\n",
      "Processed: alpr_lp_92.jpg\n",
      "Processed: alpr_lp_44.jpg\n",
      "Processed: alpr_lp_95.jpg\n",
      "Processed: alpr_lp_142.jpg\n",
      "Processed: alpr_lp_38.jpg\n",
      "Processed: alpr_lp_193.jpg\n",
      "Processed: alpr_lp_173.jpg\n",
      "Processed: alpr_lp_75.jpg\n",
      "Processed: alpr_lp_108.jpg\n",
      "Processed: alpr_lp_72.jpg\n",
      "Processed: alpr_lp_174.jpg\n",
      "Processed: alpr_lp_106.jpg\n",
      "Processed: alpr_lp_5.jpg\n",
      "Processed: alpr_lp_101.jpg\n",
      "Processed: alpr_lp_2.jpg\n",
      "Processed: alpr_lp_32.jpg\n",
      "Processed: alpr_lp_148.jpg\n",
      "Processed: alpr_lp_199.jpg\n",
      "Processed: alpr_lp_134.jpg\n",
      "Processed: alpr_lp_49.jpg\n",
      "Processed: alpr_lp_133.jpg\n",
      "Processed: alpr_lp_98.jpg\n",
      "Processed: alpr_lp_35.jpg\n",
      "Processed: alpr_lp_47.jpg\n",
      "Processed: alpr_lp_96.jpg\n",
      "Processed: alpr_lp_141.jpg\n",
      "Processed: alpr_lp_190.jpg\n",
      "Processed: alpr_lp_146.jpg\n",
      "Processed: alpr_lp_197.jpg\n",
      "Processed: alpr_lp_40.jpg\n",
      "Processed: alpr_lp_91.jpg\n",
      "Processed: alpr_lp_186.jpg\n",
      "Processed: alpr_lp_157.jpg\n",
      "Processed: alpr_lp_80.jpg\n",
      "Processed: alpr_lp_51.jpg\n",
      "Processed: alpr_lp_87.jpg\n",
      "Processed: alpr_lp_56.jpg\n",
      "Processed: alpr_lp_181.jpg\n",
      "Processed: alpr_lp_150.jpg\n",
      "Processed: alpr_lp_89.jpg\n",
      "Processed: alpr_lp_122.jpg\n",
      "Processed: alpr_lp_58.jpg\n",
      "Processed: alpr_lp_24.jpg\n",
      "Processed: alpr_lp_188.jpg\n",
      "Processed: alpr_lp_159.jpg\n",
      "Processed: alpr_lp_23.jpg\n",
      "Processed: alpr_lp_125.jpg\n",
      "Processed: alpr_lp_16.jpg\n",
      "Processed: alpr_lp_110.jpg\n",
      "Processed: alpr_lp_117.jpg\n",
      "Processed: alpr_lp_200.jpg\n",
      "Processed: alpr_lp_11.jpg\n",
      "Processed: alpr_lp_63.jpg\n",
      "Processed: alpr_lp_119.jpg\n",
      "Processed: alpr_lp_165.jpg\n",
      "Processed: alpr_lp_18.jpg\n",
      "Processed: alpr_lp_162.jpg\n",
      "Processed: alpr_lp_64.jpg\n",
      "Processed: alpr_lp_147.jpg\n",
      "Processed: alpr_lp_196.jpg\n",
      "Processed: alpr_lp_41.jpg\n",
      "Processed: alpr_lp_90.jpg\n",
      "Processed: alpr_lp_46.jpg\n",
      "Processed: alpr_lp_97.jpg\n",
      "Processed: alpr_lp_140.jpg\n",
      "Processed: alpr_lp_191.jpg\n",
      "Processed: alpr_lp_132.jpg\n",
      "Processed: alpr_lp_48.jpg\n",
      "Processed: alpr_lp_99.jpg\n",
      "Processed: alpr_lp_34.jpg\n",
      "Processed: alpr_lp_149.jpg\n",
      "Processed: alpr_lp_33.jpg\n",
      "Processed: alpr_lp_198.jpg\n",
      "Processed: alpr_lp_135.jpg\n",
      "Processed: alpr_lp_100.jpg\n",
      "Processed: alpr_lp_3.jpg\n",
      "Processed: alpr_lp_107.jpg\n",
      "Processed: alpr_lp_4.jpg\n",
      "Processed: alpr_lp_73.jpg\n",
      "Processed: alpr_lp_109.jpg\n",
      "Processed: alpr_lp_175.jpg\n",
      "Processed: alpr_lp_172.jpg\n",
      "Processed: alpr_lp_74.jpg\n",
      "Processed: alpr_lp_163.jpg\n",
      "Processed: alpr_lp_19.jpg\n",
      "Processed: alpr_lp_65.jpg\n",
      "Processed: alpr_lp_118.jpg\n",
      "Processed: alpr_lp_62.jpg\n",
      "Processed: alpr_lp_164.jpg\n",
      "Processed: alpr_lp_116.jpg\n",
      "Processed: alpr_lp_201.jpg\n",
      "Processed: alpr_lp_10.jpg\n",
      "Processed: alpr_lp_17.jpg\n",
      "Processed: alpr_lp_111.jpg\n",
      "Processed: alpr_lp_189.jpg\n",
      "Processed: alpr_lp_22.jpg\n",
      "Processed: alpr_lp_158.jpg\n",
      "Processed: alpr_lp_124.jpg\n",
      "Processed: alpr_lp_88.jpg\n",
      "Processed: alpr_lp_59.jpg\n",
      "Processed: alpr_lp_123.jpg\n",
      "Processed: alpr_lp_25.jpg\n",
      "Processed: alpr_lp_86.jpg\n",
      "Processed: alpr_lp_57.jpg\n",
      "Processed: alpr_lp_180.jpg\n",
      "Processed: alpr_lp_151.jpg\n",
      "Processed: alpr_lp_187.jpg\n",
      "Processed: alpr_lp_156.jpg\n",
      "Processed: alpr_lp_81.jpg\n",
      "Processed: alpr_lp_50.jpg\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Process all images in the input folder\n",
    "input_path = Path(input_folder)\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}\n",
    "\n",
    "image_files = [f for f in input_path.iterdir() if f.suffix in image_extensions]\n",
    "\n",
    "print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "for img_file in image_files:\n",
    "    # Read image\n",
    "    image = cv2.imread(str(img_file))\n",
    "    if image is None:\n",
    "        print(f\"Warning: Could not read {img_file.name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Process with Otsu method\n",
    "    otsu_result = otsu_global_thresholding(image)\n",
    "    otsu_output_path = os.path.join(output_folder_otsu, img_file.name)\n",
    "    cv2.imwrite(otsu_output_path, otsu_result)\n",
    "    \n",
    "    # Process with Adaptive Gaussian method\n",
    "    adaptive_result = adaptive_gaussian_thresholding(image)\n",
    "    adaptive_output_path = os.path.join(output_folder_adaptiveGaussian, img_file.name)\n",
    "    cv2.imwrite(adaptive_output_path, adaptive_result)\n",
    "    \n",
    "    print(f\"Processed: {img_file.name}\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
