{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0796aef9",
   "metadata": {},
   "source": [
    "# Guided Filter and NLM Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e455d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2289a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"images\"\n",
    "output_folder_guided = \"borui_output_guided\"\n",
    "output_folder_nlm = \"borui_output_nlm\"\n",
    "process_guided = True\n",
    "process_nlm = True\n",
    "max_side = 1024\n",
    "os.makedirs(output_folder_guided, exist_ok=True)\n",
    "os.makedirs(output_folder_nlm, exist_ok=True)\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".JPG\", \".JPEG\", \".PNG\", \".BMP\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e8df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_if_needed(image, max_side):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = max(h, w) / float(max_side)\n",
    "    if scale <= 1.0:\n",
    "        return image, 1.0\n",
    "    new_w = int(w / scale)\n",
    "    new_h = int(h / scale)\n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    return resized, scale\n",
    "\n",
    "\n",
    "def guided_filter_fast(image, radius=4, eps=1e-2):\n",
    "    src = image.astype(np.float32) / 255.0\n",
    "    if src.ndim == 2:\n",
    "        guide = src\n",
    "    else:\n",
    "        guide = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "    if hasattr(cv2, \"ximgproc\") and hasattr(cv2.ximgproc, \"guidedFilter\"):\n",
    "        gf = cv2.ximgproc.guidedFilter(guide=guide, src=src, radius=radius, eps=eps)\n",
    "        out = (gf * 255.0).clip(0, 255).astype(np.uint8)\n",
    "        return out\n",
    "    img = src\n",
    "    if img.ndim == 2:\n",
    "        img = img[:, :, None]\n",
    "    h, w, c = img.shape\n",
    "    result = np.zeros_like(img, dtype=np.float32)\n",
    "    ksize = (radius, radius)\n",
    "    for ch in range(c):\n",
    "        I = img[:, :, ch]\n",
    "        mean_I = cv2.boxFilter(I, cv2.CV_32F, ksize)\n",
    "        mean_II = cv2.boxFilter(I * I, cv2.CV_32F, ksize)\n",
    "        var_I = mean_II - mean_I * mean_I\n",
    "        a = var_I / (var_I + eps)\n",
    "        b = mean_I - a * mean_I\n",
    "        mean_a = cv2.boxFilter(a, cv2.CV_32F, ksize)\n",
    "        mean_b = cv2.boxFilter(b, cv2.CV_32F, ksize)\n",
    "        q = mean_a * I + mean_b\n",
    "        result[:, :, ch] = q\n",
    "    result = np.squeeze(result)\n",
    "    result = np.clip(result * 255.0, 0, 255).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "\n",
    "def nlm_denoise_fast(image, h=7, template_window_size=5, search_window_size=13):\n",
    "    if image.ndim == 3 and image.shape[2] == 3:\n",
    "        denoised = cv2.fastNlMeansDenoisingColored(\n",
    "            image,\n",
    "            None,\n",
    "            h,\n",
    "            h,\n",
    "            template_window_size,\n",
    "            search_window_size,\n",
    "        )\n",
    "        return denoised\n",
    "    if image.ndim == 3 and image.shape[2] == 1:\n",
    "        gray = image[:, :, 0]\n",
    "    else:\n",
    "        gray = image\n",
    "    denoised = cv2.fastNlMeansDenoising(\n",
    "        gray,\n",
    "        None,\n",
    "        h,\n",
    "        template_window_size,\n",
    "        search_window_size,\n",
    "    )\n",
    "    if image.ndim == 3 and image.shape[2] == 3:\n",
    "        denoised = cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR)\n",
    "    return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dcf1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 201 images\n",
      "processed alpr_lp_61.jpg\n",
      "processed alpr_lp_167.jpg\n",
      "processed alpr_lp_160.jpg\n",
      "processed alpr_lp_66.jpg\n",
      "processed alpr_lp_14.jpg\n",
      "processed alpr_lp_68.jpg\n",
      "processed alpr_lp_112.jpg\n",
      "processed alpr_lp_115.jpg\n",
      "processed alpr_lp_13.jpg\n",
      "processed alpr_lp_169.jpg\n",
      "processed alpr_lp_120.jpg\n",
      "processed alpr_lp_26.jpg\n",
      "processed alpr_lp_21.jpg\n",
      "processed alpr_lp_127.jpg\n",
      "processed alpr_lp_184.jpg\n",
      "processed alpr_lp_155.jpg\n",
      "processed alpr_lp_82.jpg\n",
      "processed alpr_lp_129.jpg\n",
      "processed alpr_lp_53.jpg\n",
      "processed alpr_lp_85.jpg\n",
      "processed alpr_lp_54.jpg\n",
      "processed alpr_lp_183.jpg\n",
      "processed alpr_lp_152.jpg\n",
      "processed alpr_lp_28.jpg\n",
      "processed alpr_lp_45.jpg\n",
      "processed alpr_lp_94.jpg\n",
      "processed alpr_lp_39.jpg\n",
      "processed alpr_lp_143.jpg\n",
      "processed alpr_lp_192.jpg\n",
      "processed alpr_lp_144.jpg\n",
      "processed alpr_lp_195.jpg\n",
      "processed alpr_lp_42.jpg\n",
      "processed alpr_lp_138.jpg\n",
      "processed alpr_lp_93.jpg\n",
      "processed alpr_lp_30.jpg\n",
      "processed alpr_lp_136.jpg\n",
      "processed alpr_lp_131.jpg\n",
      "processed alpr_lp_37.jpg\n",
      "processed alpr_lp_104.jpg\n",
      "processed alpr_lp_7.jpg\n",
      "processed alpr_lp_178.jpg\n",
      "processed alpr_lp_103.jpg\n",
      "processed alpr_lp_79.jpg\n",
      "processed alpr_lp_171.jpg\n",
      "processed alpr_lp_77.jpg\n",
      "processed alpr_lp_70.jpg\n",
      "processed alpr_lp_9.jpg\n",
      "processed alpr_lp_176.jpg\n",
      "processed alpr_lp_84.jpg\n",
      "processed alpr_lp_55.jpg\n",
      "processed alpr_lp_182.jpg\n",
      "processed alpr_lp_29.jpg\n",
      "processed alpr_lp_153.jpg\n",
      "processed alpr_lp_185.jpg\n",
      "processed alpr_lp_154.jpg\n",
      "processed alpr_lp_83.jpg\n",
      "processed alpr_lp_52.jpg\n",
      "processed alpr_lp_128.jpg\n",
      "processed alpr_lp_20.jpg\n",
      "processed alpr_lp_126.jpg\n",
      "processed alpr_lp_121.jpg\n",
      "processed alpr_lp_27.jpg\n",
      "processed alpr_lp_114.jpg\n",
      "processed alpr_lp_168.jpg\n",
      "processed alpr_lp_12.jpg\n",
      "processed alpr_lp_15.jpg\n",
      "processed alpr_lp_113.jpg\n",
      "processed alpr_lp_69.jpg\n",
      "processed alpr_lp_161.jpg\n",
      "processed alpr_lp_67.jpg\n",
      "processed alpr_lp_60.jpg\n",
      "processed alpr_lp_166.jpg\n",
      "processed alpr_lp_71.jpg\n",
      "processed alpr_lp_8.jpg\n",
      "processed alpr_lp_177.jpg\n",
      "processed alpr_lp_170.jpg\n",
      "processed alpr_lp_76.jpg\n",
      "processed alpr_lp_78.jpg\n",
      "processed alpr_lp_102.jpg\n",
      "processed alpr_lp_1.jpg\n",
      "processed alpr_lp_105.jpg\n",
      "processed alpr_lp_6.jpg\n",
      "processed alpr_lp_179.jpg\n",
      "processed alpr_lp_130.jpg\n",
      "processed alpr_lp_36.jpg\n",
      "processed alpr_lp_31.jpg\n",
      "processed alpr_lp_137.jpg\n",
      "processed alpr_lp_145.jpg\n",
      "processed alpr_lp_194.jpg\n",
      "processed alpr_lp_139.jpg\n",
      "processed alpr_lp_43.jpg\n",
      "processed alpr_lp_92.jpg\n",
      "processed alpr_lp_44.jpg\n",
      "processed alpr_lp_95.jpg\n",
      "processed alpr_lp_142.jpg\n",
      "processed alpr_lp_38.jpg\n",
      "processed alpr_lp_193.jpg\n",
      "processed alpr_lp_173.jpg\n",
      "processed alpr_lp_75.jpg\n",
      "processed alpr_lp_108.jpg\n",
      "processed alpr_lp_72.jpg\n",
      "processed alpr_lp_174.jpg\n",
      "processed alpr_lp_106.jpg\n",
      "processed alpr_lp_5.jpg\n",
      "processed alpr_lp_101.jpg\n",
      "processed alpr_lp_2.jpg\n",
      "processed alpr_lp_32.jpg\n",
      "processed alpr_lp_148.jpg\n",
      "processed alpr_lp_199.jpg\n",
      "processed alpr_lp_134.jpg\n",
      "processed alpr_lp_49.jpg\n",
      "processed alpr_lp_133.jpg\n",
      "processed alpr_lp_98.jpg\n",
      "processed alpr_lp_35.jpg\n",
      "processed alpr_lp_47.jpg\n",
      "processed alpr_lp_96.jpg\n",
      "processed alpr_lp_141.jpg\n",
      "processed alpr_lp_190.jpg\n",
      "processed alpr_lp_146.jpg\n",
      "processed alpr_lp_197.jpg\n",
      "processed alpr_lp_40.jpg\n",
      "processed alpr_lp_91.jpg\n",
      "processed alpr_lp_186.jpg\n",
      "processed alpr_lp_157.jpg\n",
      "processed alpr_lp_80.jpg\n",
      "processed alpr_lp_51.jpg\n",
      "processed alpr_lp_87.jpg\n",
      "processed alpr_lp_56.jpg\n",
      "processed alpr_lp_181.jpg\n",
      "processed alpr_lp_150.jpg\n",
      "processed alpr_lp_89.jpg\n",
      "processed alpr_lp_122.jpg\n",
      "processed alpr_lp_58.jpg\n",
      "processed alpr_lp_24.jpg\n",
      "processed alpr_lp_188.jpg\n",
      "processed alpr_lp_159.jpg\n",
      "processed alpr_lp_23.jpg\n",
      "processed alpr_lp_125.jpg\n",
      "processed alpr_lp_16.jpg\n",
      "processed alpr_lp_110.jpg\n",
      "processed alpr_lp_117.jpg\n",
      "processed alpr_lp_200.jpg\n",
      "processed alpr_lp_11.jpg\n",
      "processed alpr_lp_63.jpg\n",
      "processed alpr_lp_119.jpg\n",
      "processed alpr_lp_165.jpg\n",
      "processed alpr_lp_18.jpg\n",
      "processed alpr_lp_162.jpg\n",
      "processed alpr_lp_64.jpg\n",
      "processed alpr_lp_147.jpg\n",
      "processed alpr_lp_196.jpg\n",
      "processed alpr_lp_41.jpg\n",
      "processed alpr_lp_90.jpg\n",
      "processed alpr_lp_46.jpg\n",
      "processed alpr_lp_97.jpg\n",
      "processed alpr_lp_140.jpg\n",
      "processed alpr_lp_191.jpg\n",
      "processed alpr_lp_132.jpg\n",
      "processed alpr_lp_48.jpg\n",
      "processed alpr_lp_99.jpg\n",
      "processed alpr_lp_34.jpg\n",
      "processed alpr_lp_149.jpg\n",
      "processed alpr_lp_33.jpg\n",
      "processed alpr_lp_198.jpg\n",
      "processed alpr_lp_135.jpg\n",
      "processed alpr_lp_100.jpg\n",
      "processed alpr_lp_3.jpg\n",
      "processed alpr_lp_107.jpg\n",
      "processed alpr_lp_4.jpg\n",
      "processed alpr_lp_73.jpg\n",
      "processed alpr_lp_109.jpg\n",
      "processed alpr_lp_175.jpg\n",
      "processed alpr_lp_172.jpg\n",
      "processed alpr_lp_74.jpg\n",
      "processed alpr_lp_163.jpg\n",
      "processed alpr_lp_19.jpg\n",
      "processed alpr_lp_65.jpg\n",
      "processed alpr_lp_118.jpg\n",
      "processed alpr_lp_62.jpg\n",
      "processed alpr_lp_164.jpg\n",
      "processed alpr_lp_116.jpg\n",
      "processed alpr_lp_201.jpg\n",
      "processed alpr_lp_10.jpg\n",
      "processed alpr_lp_17.jpg\n",
      "processed alpr_lp_111.jpg\n",
      "processed alpr_lp_189.jpg\n",
      "processed alpr_lp_22.jpg\n",
      "processed alpr_lp_158.jpg\n",
      "processed alpr_lp_124.jpg\n",
      "processed alpr_lp_88.jpg\n",
      "processed alpr_lp_59.jpg\n",
      "processed alpr_lp_123.jpg\n",
      "processed alpr_lp_25.jpg\n",
      "processed alpr_lp_86.jpg\n",
      "processed alpr_lp_57.jpg\n",
      "processed alpr_lp_180.jpg\n",
      "processed alpr_lp_151.jpg\n",
      "processed alpr_lp_187.jpg\n",
      "processed alpr_lp_156.jpg\n",
      "processed alpr_lp_81.jpg\n",
      "processed alpr_lp_50.jpg\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "input_path = Path(input_folder)\n",
    "files = [f for f in input_path.iterdir() if f.suffix in image_extensions]\n",
    "print(f\"found {len(files)} images\")\n",
    "for img_file in files:\n",
    "    image = cv2.imread(str(img_file))\n",
    "    if image is None:\n",
    "        print(f\"skip {img_file.name}\")\n",
    "        continue\n",
    "    img_small, scale = resize_if_needed(image, max_side)\n",
    "    if process_guided:\n",
    "        guided_img = guided_filter_fast(img_small, radius=4, eps=1e-2)\n",
    "        if scale != 1.0:\n",
    "            guided_img = cv2.resize(\n",
    "                guided_img,\n",
    "                (image.shape[1], image.shape[0]),\n",
    "                interpolation=cv2.INTER_CUBIC,\n",
    "            )\n",
    "        out_path_g = os.path.join(output_folder_guided, img_file.name)\n",
    "        cv2.imwrite(out_path_g, guided_img)\n",
    "    if process_nlm:\n",
    "        nlm_img = nlm_denoise_fast(img_small, h=7, template_window_size=5, search_window_size=13)\n",
    "        if scale != 1.0:\n",
    "            nlm_img = cv2.resize(\n",
    "                nlm_img,\n",
    "                (image.shape[1], image.shape[0]),\n",
    "                interpolation=cv2.INTER_CUBIC,\n",
    "            )\n",
    "        out_path_n = os.path.join(output_folder_nlm, img_file.name)\n",
    "        cv2.imwrite(out_path_n, nlm_img)\n",
    "    print(f\"processed {img_file.name}\")\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
