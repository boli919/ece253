{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8e7fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941f8b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "images dir: dichen_output_otsu\n",
      "csv file: val_annotations.csv\n",
      "baseline ckpt: final_model.pth\n",
      "finetuned ckpt: finetuned_model.pth\n"
     ]
    }
   ],
   "source": [
    "IMAGES_DIR = \"borui_out\"\n",
    "CSV_FILE = \"val_annotations.csv\"\n",
    "\n",
    "BASELINE_CKPT = \"final_model.pth\"\n",
    "FINETUNED_CKPT = \"finetuned_model.pth\"\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "SCORE_THRESH = 0.5\n",
    "IOU_THRESH = 0.5\n",
    "\n",
    "print(\"device:\", device)\n",
    "print(\"images dir:\", IMAGES_DIR)\n",
    "print(\"csv file:\", CSV_FILE)\n",
    "print(\"baseline ckpt:\", BASELINE_CKPT)\n",
    "print(\"finetuned ckpt:\", FINETUNED_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a32562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NumberPlateDataset(Dataset):\n",
    "    def __init__(self, csv_file, images_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        if \"filename\" not in self.data_frame.columns:\n",
    "            raise ValueError(\"CSV must contain a 'filename' column.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data_frame.iloc[idx]\n",
    "        img_path = os.path.join(self.images_dir, row[\"filename\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        xmin = float(row[\"xmin\"])\n",
    "        ymin = float(row[\"ymin\"])\n",
    "        xmax = float(row[\"xmax\"])\n",
    "        ymax = float(row[\"ymax\"])\n",
    "\n",
    "        boxes = torch.as_tensor([[xmin, ymin, xmax, ymax]], dtype=torch.float32)\n",
    "        labels = torch.ones((1,), dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    return list(images), list(targets)\n",
    "\n",
    "\n",
    "eval_transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "eval_dataset = NumberPlateDataset(CSV_FILE, IMAGES_DIR, transform=eval_transform)\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if device.type == \"cuda\" else False,\n",
    ")\n",
    "\n",
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec11c5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models_ready'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(num_classes, ckpt_path):\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    if ckpt_path is not None and os.path.exists(ckpt_path):\n",
    "        state_dict = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = build_model(NUM_CLASSES, BASELINE_CKPT)\n",
    "finetuned_model = build_model(NUM_CLASSES, FINETUNED_CKPT)\n",
    "\n",
    "baseline_model.eval()\n",
    "finetuned_model.eval()\n",
    "\n",
    "\"models_ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d08787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "\n",
    "    inter_w = max(0.0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0.0, inter_y2 - inter_y1)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)\n",
    "    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)\n",
    "    union = area_a + area_b - inter\n",
    "\n",
    "    if union <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    return inter / union\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_metrics(model, data_loader, device, score_thresh=0.5, iou_thresh=0.5):\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    detected = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "\n",
    "        for out, tgt in zip(outputs, targets):\n",
    "            total += 1\n",
    "\n",
    "            gt_boxes = tgt[\"boxes\"].cpu().numpy()\n",
    "            pred_boxes = out[\"boxes\"].detach().cpu().numpy()\n",
    "            scores = out[\"scores\"].detach().cpu().numpy()\n",
    "\n",
    "            if len(pred_boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            idx = int(np.argmax(scores))\n",
    "            if scores[idx] < score_thresh:\n",
    "                continue\n",
    "\n",
    "            pred = pred_boxes[idx]\n",
    "            gt = gt_boxes[0]\n",
    "\n",
    "            iou = box_iou(pred, gt)\n",
    "\n",
    "            if iou >= iou_thresh:\n",
    "                detected += 1\n",
    "\n",
    "            ious.append(iou)\n",
    "\n",
    "    avg_iou = float(np.mean(ious)) if len(ious) > 0 else 0.0\n",
    "    det_rate = detected / max(1, total)\n",
    "    return avg_iou, det_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199087c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 19\n",
      "Baseline  avg IoU: 0.296835290061103\n",
      "Baseline  det rate: 0.15789473684210525\n",
      "Finetuned avg IoU: 0.5737715271803049\n",
      "Finetuned det rate: 0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "baseline_iou, baseline_det = evaluate_metrics(\n",
    "    baseline_model,\n",
    "    eval_loader,\n",
    "    device,\n",
    "    score_thresh=SCORE_THRESH,\n",
    "    iou_thresh=IOU_THRESH,\n",
    ")\n",
    "\n",
    "finetuned_iou, finetuned_det = evaluate_metrics(\n",
    "    finetuned_model,\n",
    "    eval_loader,\n",
    "    device,\n",
    "    score_thresh=SCORE_THRESH,\n",
    "    iou_thresh=IOU_THRESH,\n",
    ")\n",
    "\n",
    "print(\"dataset size:\", len(eval_dataset))\n",
    "print(\"Baseline  avg IoU:\", baseline_iou)\n",
    "print(\"Baseline  det rate:\", baseline_det)\n",
    "print(\"Finetuned avg IoU:\", finetuned_iou)\n",
    "print(\"Finetuned det rate:\", finetuned_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e6a10-1ca2-4e68-ab23-986a61b6caf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
