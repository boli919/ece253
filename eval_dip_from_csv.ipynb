{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8e7fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941f8b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "eval dirs: ['borui_output_guided', 'borui_output_nlm', 'dichen_output_otsu', 'haixin_output_canny', 'haixin_output_scharr', 'output_canny_custom', 'dichen_output_adaptiveGaussian']\n"
     ]
    }
   ],
   "source": [
    "EVAL_DIRS = [\n",
    "    \"borui_output_guided\",\n",
    "    \"borui_output_nlm\",\n",
    "    \"dichen_output_otsu\",\n",
    "    \"haixin_output_canny\",\n",
    "    \"haixin_output_scharr\",\n",
    "    \"output_canny_custom\",\n",
    "    \"dichen_output_adaptiveGaussian\"\n",
    "]\n",
    "\n",
    "BASELINE_CKPT = \"final_model.pth\"\n",
    "FINETUNED_CKPT = \"finetuned_model.pth\"\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "SCORE_THRESH = 0.5\n",
    "IOU_THRESH = 0.5\n",
    "\n",
    "print(\"device:\", device)\n",
    "print(\"eval dirs:\", EVAL_DIRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a32562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset_ready'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NumberPlateDataset(Dataset):\n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "        self.files = [\n",
    "            f\n",
    "            for f in os.listdir(images_dir)\n",
    "            if os.path.splitext(f)[1].lower() in exts\n",
    "        ]\n",
    "        self.files.sort()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.files[idx]\n",
    "        img_path = os.path.join(self.images_dir, filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = image.size\n",
    "\n",
    "        boxes = torch.tensor([[0.0, 0.0, float(w), float(h)]], dtype=torch.float32)\n",
    "        labels = torch.tensor([1], dtype=torch.int64)\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "        }\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [b[0] for b in batch]\n",
    "    targets = [b[1] for b in batch]\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "eval_transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "\n",
    "def make_loader(images_dir):\n",
    "    dataset = NumberPlateDataset(images_dir, transform=eval_transform)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == \"cuda\" else False,\n",
    "    )\n",
    "    return dataset, loader\n",
    "\n",
    "\n",
    "\"dataset_ready\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec11c5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models_ready'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(num_classes, ckpt_path):\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    if ckpt_path is not None and os.path.exists(ckpt_path):\n",
    "        state_dict = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = build_model(NUM_CLASSES, BASELINE_CKPT)\n",
    "finetuned_model = build_model(NUM_CLASSES, FINETUNED_CKPT)\n",
    "\n",
    "baseline_model.eval()\n",
    "finetuned_model.eval()\n",
    "\n",
    "\"models_ready\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d08787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "\n",
    "    inter_w = max(0.0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0.0, inter_y2 - inter_y1)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)\n",
    "    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)\n",
    "    union = area_a + area_b - inter\n",
    "\n",
    "    if union <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    return inter / union\n",
    "\n",
    "\n",
    "def evaluate_metrics(model, data_loader, device, score_thresh=0.5, iou_thresh=0.5):\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    detected = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "\n",
    "            for output, target in zip(outputs, targets):\n",
    "                gt_boxes = target[\"boxes\"].cpu().numpy()\n",
    "                if gt_boxes.shape[0] == 0:\n",
    "                    continue\n",
    "\n",
    "                total += 1\n",
    "\n",
    "                scores = output[\"scores\"].detach().cpu().numpy()\n",
    "                boxes = output[\"boxes\"].detach().cpu().numpy()\n",
    "\n",
    "                keep = scores >= score_thresh\n",
    "                if keep.sum() == 0:\n",
    "                    ious.append(0.0)\n",
    "                    continue\n",
    "\n",
    "                scores_keep = scores[keep]\n",
    "                boxes_keep = boxes[keep]\n",
    "\n",
    "                idx = scores_keep.argmax()\n",
    "                pred = boxes_keep[idx]\n",
    "                gt = gt_boxes[0]\n",
    "\n",
    "                iou = box_iou(pred, gt)\n",
    "                ious.append(iou)\n",
    "\n",
    "                if iou >= iou_thresh:\n",
    "                    detected += 1\n",
    "\n",
    "    avg_iou = float(np.mean(ious)) if len(ious) > 0 else 0.0\n",
    "    det_rate = detected / max(1, total)\n",
    "    return avg_iou, det_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199087c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== borui_output_guided ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.056965666868265215\n",
      "Baseline  det rate: 0.03980099502487562\n",
      "Finetuned avg IoU: 0.007144599532087644\n",
      "Finetuned det rate: 0.004975124378109453\n",
      "========== borui_output_nlm ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.07853886309723875\n",
      "Baseline  det rate: 0.06467661691542288\n",
      "Finetuned avg IoU: 0.006786071459081636\n",
      "Finetuned det rate: 0.004975124378109453\n",
      "========== dichen_output_otsu ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.005732011519701438\n",
      "Baseline  det rate: 0.004975124378109453\n",
      "Finetuned avg IoU: 0.0006610024181792317\n",
      "Finetuned det rate: 0.0\n",
      "========== haixin_output_canny ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.02690859484215225\n",
      "Baseline  det rate: 0.009950248756218905\n",
      "Finetuned avg IoU: 0.02572658176149302\n",
      "Finetuned det rate: 0.0\n",
      "========== haixin_output_scharr ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.0033537792180901144\n",
      "Baseline  det rate: 0.0\n",
      "Finetuned avg IoU: 4.312993300643133e-05\n",
      "Finetuned det rate: 0.0\n",
      "========== output_canny_custom ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.02408449731788028\n",
      "Baseline  det rate: 0.004975124378109453\n",
      "Finetuned avg IoU: 0.024763343373860294\n",
      "Finetuned det rate: 0.0\n",
      "========== dichen_output_adaptiveGaussian ==========\n",
      "num images: 201\n",
      "Baseline  avg IoU: 0.008239970733620115\n",
      "Baseline  det rate: 0.0\n",
      "Finetuned avg IoU: 0.0013779772663331446\n",
      "Finetuned det rate: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dir': 'borui_output_guided',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.056965666868265215,\n",
       "  'baseline_det': 0.03980099502487562,\n",
       "  'finetuned_iou': 0.007144599532087644,\n",
       "  'finetuned_det': 0.004975124378109453},\n",
       " {'dir': 'borui_output_nlm',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.07853886309723875,\n",
       "  'baseline_det': 0.06467661691542288,\n",
       "  'finetuned_iou': 0.006786071459081636,\n",
       "  'finetuned_det': 0.004975124378109453},\n",
       " {'dir': 'dichen_output_otsu',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.005732011519701438,\n",
       "  'baseline_det': 0.004975124378109453,\n",
       "  'finetuned_iou': 0.0006610024181792317,\n",
       "  'finetuned_det': 0.0},\n",
       " {'dir': 'haixin_output_canny',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.02690859484215225,\n",
       "  'baseline_det': 0.009950248756218905,\n",
       "  'finetuned_iou': 0.02572658176149302,\n",
       "  'finetuned_det': 0.0},\n",
       " {'dir': 'haixin_output_scharr',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.0033537792180901144,\n",
       "  'baseline_det': 0.0,\n",
       "  'finetuned_iou': 4.312993300643133e-05,\n",
       "  'finetuned_det': 0.0},\n",
       " {'dir': 'output_canny_custom',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.02408449731788028,\n",
       "  'baseline_det': 0.004975124378109453,\n",
       "  'finetuned_iou': 0.024763343373860294,\n",
       "  'finetuned_det': 0.0},\n",
       " {'dir': 'dichen_output_adaptiveGaussian',\n",
       "  'n_images': 201,\n",
       "  'baseline_iou': 0.008239970733620115,\n",
       "  'baseline_det': 0.0,\n",
       "  'finetuned_iou': 0.0013779772663331446,\n",
       "  'finetuned_det': 0.0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for images_dir in EVAL_DIRS:\n",
    "    if not os.path.isdir(images_dir):\n",
    "        print(f\"[skip] {images_dir} not found\")\n",
    "        continue\n",
    "\n",
    "    dataset, loader = make_loader(images_dir)\n",
    "\n",
    "    baseline_iou, baseline_det = evaluate_metrics(\n",
    "        baseline_model,\n",
    "        loader,\n",
    "        device,\n",
    "        score_thresh=SCORE_THRESH,\n",
    "        iou_thresh=IOU_THRESH,\n",
    "    )\n",
    "\n",
    "    finetuned_iou, finetuned_det = evaluate_metrics(\n",
    "        finetuned_model,\n",
    "        loader,\n",
    "        device,\n",
    "        score_thresh=SCORE_THRESH,\n",
    "        iou_thresh=IOU_THRESH,\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"dir\": images_dir,\n",
    "            \"n_images\": len(dataset),\n",
    "            \"baseline_iou\": baseline_iou,\n",
    "            \"baseline_det\": baseline_det,\n",
    "            \"finetuned_iou\": finetuned_iou,\n",
    "            \"finetuned_det\": finetuned_det,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"==========\", images_dir, \"==========\")\n",
    "    print(\"num images:\", len(dataset))\n",
    "    print(\"Baseline  avg IoU:\", baseline_iou)\n",
    "    print(\"Baseline  det rate:\", baseline_det)\n",
    "    print(\"Finetuned avg IoU:\", finetuned_iou)\n",
    "    print(\"Finetuned det rate:\", finetuned_det)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086b34a-68b6-44ce-a4e2-e32015acb585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
